# Exponentiation

Consider the problem of computing the exponential of a given number.
We would like a procedure that takes as arguments a base b and a posi-
tive integer exponent n and computes b n . One way to do this is via the
recursive definition

which translates readily into the procedure
(define (expt b n)
(if (= n 0)
1
(* b (expt b (- n 1)))))
is is a linear recursive process, which requires Θ(n) steps and Θ(n)
space. Just as with factorial, we can readily formulate an equivalent lin-
ear iteration:

```clojure
(define (expt b n)
(expt-iter b n 1))
(define (expt-iter b counter product)
(if (= counter 0)
product
(expt-iter b
(- counter 1)
(* b product))))
```

is version requires Θ(n) steps and Θ(1) space.
We can compute exponentials in fewer steps by using successive
squaring. For instance, rather than computing $b^8$ as

$$ b \cdot (b \cdot (b \cdot (b \cdot (b \cdot (b \cdot (b \cdot b)))))) $$

we can compute it using three multiplications:

$$ b^2 = b \cdot  b $$
$$ b^4 = b^2 \cdot b^2 $$
$$ b^8 = b^4 \cdot b^4 $$

is method works fine for exponents that are powers of 2. We can
also take advantage of successive squaring in computing exponentials
in general if we use the rule

If `n` is even
$$ b^n = (b^{n/2})^2 $$

If `n` is odd
$$ b^n = b \cdot b^{n-1} $$

We can express this method as a procedure:

```clojure
(defn fast-expt [b n]
  (cond (= n 0)
        1

        (even? n)
        (square (fast-expt b (/ n 2)))

        :else
        (* b (fast-expt b (dec n)))))
```

e process evolved by fast-expt grows logarithmically with n in both
space and number of steps. To see this, observe that computing b 2n us-
ing fast-expt requires only one more multiplication than computing
b n . e size of the exponent we can compute therefore doubles (approx-
imately) with every new multiplication we are allowed. us, the num-
ber of multiplications required for an exponent of n grows about as fast
as the logarithm of n to the base 2. e process has Θ(log n) growth. 37
e difference between Θ(log n) growth and Θ(n) growth becomes
striking as n becomes large. For example, fast-expt for n = 1000 re-
quires only 14 multiplications. 38 It is also possible to use the idea of
successive squaring to devise an iterative algorithm that computes ex-
ponentials with a logarithmic number of steps (see Exercise 1.16), al-
though, as is oen the case with iterative algorithms, this is not wrien
down so straightforwardly as the recursive algorithm
